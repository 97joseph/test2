# ğŸŒ Ask the Web â€“ AI-Powered Web Q\&A App

**Ask the Web** is a Streamlit-based application that allows users to ask natural language questions and get accurate, readable, and cited answers powered by OpenAI's GPT API and real-time web data.

> ğŸ” Ask a question â†’ ğŸŒ Search the web â†’ ğŸ¤– Get a GPT answer â†’ ğŸ“ View citations and analytics

---

## ğŸš€ Features

* ğŸ”— **Real-time web search** from Google, Bing, DuckDuckGo, and Brave
* ğŸ¤– **OpenAI GPT-4o-mini** for generating natural language answers
* ğŸ§  **Citations** and sources for every answer
* ğŸ“Š **Answer quality metrics**: accuracy, relevance, precision, readability, etc.
* ğŸ“ˆ **Telemetry dashboard**: token usage, latency, API calls
* âš¡ï¸ **Asynchronous fetching** and response caching for performance

---

Here's an updated version of your `README.md` file with a new section added to document the `test_app.py` test suite and how to run the tests using `pytest`.

---

### âœ… Updated `README.md`

````markdown
# Async Web Query & Analysis Tool

This project fetches data from the web, extracts citations, generates answers using OpenAI, analyzes metrics like relevance and factuality, and displays the results using Streamlit.

---

## ğŸ§° Requirements

Install dependencies:

```bash
pip install -r requirements.txt
````

---

## ğŸš€ Usage

Start the Streamlit app:

```bash
streamlit run app.py
```

---

## ğŸ§ª Running Tests

Unit tests are provided in the `test_app.py` file. They cover:

* `fetch_web_data()` and its error handling
* `fetch_citations()` and its error handling
* `analyze_metrics()` output structure and values
* `get_answer()` for successful and edge-case responses from OpenAI API

To run the test suite:

```bash
pytest test_app.py
```

Ensure you have `pytest` installed:

```bash
pip install pytest
```

---

## ğŸ“ File Structure

```text
.
â”œâ”€â”€ app.py              # Main Streamlit app
â”œâ”€â”€ test_app.py         # Pytest unit test suite
â”œâ”€â”€ requirements.txt    # Python dependencies
â””â”€â”€ README.md           # Project documentation
```

---

## ğŸ” Environment Variables

Set the following environment variables for API access:

* `OPENAI_API_KEY` â€“ Your OpenAI key
* (Optional) Any other API keys used inside `app.py`

You can set them using `.env` or your terminal shell:

```bash
export OPENAI_API_KEY=your_key
```

---

## ğŸ§  Features Tested in `test_app.py`

* Full async I/O testing with `aiohttp`
* Exception handling verification
* Mocked API responses and tokens
* Metric evaluation logic
* Telemetry validation from API responses

---

## ğŸ‘©â€ğŸ”¬ License

MIT License

```

Let me know if you'd like me to generate a `requirements.txt` for the test dependencies or add CI instructions (e.g., GitHub Actions).
```


## ğŸ“¸ Demo

![Ask the Web Screenshot](screenshot.png) <sub>(Add your own screenshot here)</sub>

---

## ğŸ§° Tech Stack

* [Streamlit](https://streamlit.io/) â€“ UI
* [OpenAI API](https://openai.com/) â€“ LLM response generation
* [aiohttp](https://docs.aiohttp.org/) â€“ Async HTTP requests
* [BeautifulSoup](https://www.crummy.com/software/BeautifulSoup/) â€“ HTML parsing
* [dotenv](https://pypi.org/project/python-dotenv/) â€“ Environment variable management
* [Python asyncio](https://docs.python.org/3/library/asyncio.html) â€“ Asynchronous event loop

---

## ğŸ“¦ Setup

### 1. Clone the Repository

```bash
git clone https://github.com/your-username/ask-the-web.git
cd ask-the-web
```

### 2. Install Dependencies

```bash
pip install -r requirements.txt
```

### 3. Configure Environment Variables

Create a `.env` file in the project root:

```env
OPENAI_API_KEY=your_openai_api_key
```

### 4. Run the App

```bash
streamlit run app.py
```

---

## âœ¨ How It Works

1. User enters a question in the UI.
2. The app fetches real-time search results from multiple search engines using asynchronous HTTP requests.
3. Extracted snippets are passed to OpenAI's GPT model to generate a coherent answer.
4. Answer and its citations are displayed with quality metrics and performance telemetry.

---

## ğŸ“ˆ Metrics & Analytics

The app includes two dashboards:

* **Telemetry**: Token usage, latency, and API stats
* **Analytics**: Answer quality breakdown (relevance, factuality, precision, etc.)

> Metrics are currently placeholder values and can be enhanced with NLP techniques or similarity scoring.

---

## âœ… TODO

* [ ] Enhance web scraping with robust selectors or an API-based approach
* [ ] Use semantic search or embedding models for better web data relevance
* [ ] Implement actual metrics analysis (e.g., cosine similarity with trusted content)
* [ ] Add feedback mechanism to rate answers

---

## ğŸ›¡ Disclaimers

* This app uses AI-generated content and may contain inaccuracies.
* Web scraping is subject to the terms of service of the target websites.
* Intended for educational and experimental use.

---

## ğŸ“„ License

MIT License

---

## ğŸ™Œ Acknowledgements

* OpenAI for GPT models
* Streamlit for interactive Python UI
* Python community for async tools and web scraping libraries

---

## ğŸ“¬ Contact

Created by [Joseph Kibira](https://github.com/your-username) â€“ feel free to reach out or contribute!


